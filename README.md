# Personal Safety Assistant – Chat Moderation with ML
📌 Overview

This project is a real-time chat application integrated with Machine Learning models to detect and prevent harmful or inappropriate content. The system ensures safe digital communication by flagging toxic messages, issuing warnings, and enforcing penalties such as temporary bans or suspensions.

Unlike regular chat apps, this platform prioritizes user safety by combining backend functionality with smooth user experience across web and mobile platforms.

🚀 Features

🔹 Real-time Chat – Connect via IP/Username for seamless messaging.

🔹 ML-based Moderation – Detect harmful/toxic/inappropriate chats using trained models.

🔹 Multiple Algorithms – Logistic Regression, SVM, and LSTM models for comparison and efficiency.

🔹 Warning & Penalty System – Displays alerts, temporary bans, or suspensions for violators.

🔹 Cross-Platform – Accessible on both web and mobile.

🔹 Admin Control – Allows monitoring of flagged conversations for transparency.

🧠 Machine Learning Models Used

Logistic Regression – Lightweight, interpretable baseline model.

Support Vector Machine (SVM) – Effective for high-dimensional text classification.

Long Short-Term Memory (LSTM) – Deep learning model for contextual chat understanding.

The models were trained on toxic/harassment datasets to identify harmful patterns in real-time conversations.

🛠️ Tech Stack

Frontend: HTML, CSS, JavaScript (Mobile + Web)

Backend: Python, Flask/Django (choose whichever you used)

Database: SQLite / MySQL (your choice)

Machine Learning: Scikit-learn, TensorFlow/Keras, NLP preprocessing

Hosting/Version Control: GitHub

⚙️ Installation & Setup
1️⃣ Clone the Repository
git clone https://github.com/rachitkothadia/SecureChat.git
cd SecureChat

2️⃣ Install Dependencies
npm install

3️⃣ Start the Application
npm start


The app will run on:
👉 http://localhost:3000/
 (default)
 
🔮 Future Scope

Integrating transformer-based models (BERT, RoBERTa) for advanced detection.

Adding end-to-end encryption for secure chats.

Implementing user reputation scoring.

Expanding to voice chat moderation.

📚 Academic Context

This project was developed as a Capstone Project for the Diploma in Artificial Intelligence & Machine Learning. It demonstrates practical application of ML in cyber safety, digital well-being, and AI ethics.

👨‍💻 Contributors

Rachit Ritesh Kothadia – Developer & ML Engineer
Mayank Satish Dandane - Devoloper & ML Engineer

📜 License
This project is for academic and research purposes only.
